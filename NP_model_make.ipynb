{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2W9QxaRcivIy",
        "outputId": "badc4ec8-62d1-4d62-e57d-90ae46c86357"
      },
      "outputs": [],
      "source": [
        "import os, copy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "iHR5KFRKivIz",
        "outputId": "5bc9df10-96b0-4071-d187-a656ad645d13"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>intent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>스페인 마드리드에 여행가면 하고 싶은거 있어?</td>\n",
              "      <td>(지시) 질문하기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>나는 키키 축구 보고 싶네</td>\n",
              "      <td>(단언) 주장하기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>축구팀 어디 경기 말이야?</td>\n",
              "      <td>(지시) 질문하기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>거기 레알 마드리드 홈구장이 있잖아 하하</td>\n",
              "      <td>(단언) 진술하기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>아 그 베르나베우였나?</td>\n",
              "      <td>(지시) 질문하기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>740672</th>\n",
              "      <td>말이라도 하는 게 낫겠지?? 오백 올려 주면 진짜 좋겠다...</td>\n",
              "      <td>(단언) 주장하기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>740673</th>\n",
              "      <td>최저시급도 올랐는데 연봉도 당연히 올라야 되는 것 아냐?!</td>\n",
              "      <td>(지시) 질문하기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>740674</th>\n",
              "      <td>나는 재밌어서 하루 만에 다 봤는데.</td>\n",
              "      <td>(단언) 주장하기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>740675</th>\n",
              "      <td>헐, 엄청 긴데 피곤했겠다.</td>\n",
              "      <td>(단언) 주장하기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>740676</th>\n",
              "      <td>나는 시즌 1부터 봐야겠어.</td>\n",
              "      <td>(언약) 약속하기(제3자와)/(개인적 수준)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>740677 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  sentence                    intent\n",
              "0                스페인 마드리드에 여행가면 하고 싶은거 있어?                 (지시) 질문하기\n",
              "1                           나는 키키 축구 보고 싶네                 (단언) 주장하기\n",
              "2                           축구팀 어디 경기 말이야?                 (지시) 질문하기\n",
              "3                   거기 레알 마드리드 홈구장이 있잖아 하하                 (단언) 진술하기\n",
              "4                             아 그 베르나베우였나?                 (지시) 질문하기\n",
              "...                                    ...                       ...\n",
              "740672  말이라도 하는 게 낫겠지?? 오백 올려 주면 진짜 좋겠다...                 (단언) 주장하기\n",
              "740673    최저시급도 올랐는데 연봉도 당연히 올라야 되는 것 아냐?!                 (지시) 질문하기\n",
              "740674                나는 재밌어서 하루 만에 다 봤는데.                 (단언) 주장하기\n",
              "740675                     헐, 엄청 긴데 피곤했겠다.                 (단언) 주장하기\n",
              "740676                     나는 시즌 1부터 봐야겠어.  (언약) 약속하기(제3자와)/(개인적 수준)\n",
              "\n",
              "[740677 rows x 2 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "origin_df = pd.read_csv('/home/inter/chat_MBTI/make_dataset/intent_model_dataset.csv')\n",
        "df = copy.deepcopy(origin_df)\n",
        "df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
        "df.drop(df.loc[df['sentence'].str.contains('\\*')].index, axis=0, inplace=True)\n",
        "df = df.loc[df['sentence'].str.len() <= 100]\n",
        "df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "\n",
        "df.loc[(df['sentence'].str.contains('응') & df['sentence'].str.contains('좋아')), 'intent'] = '긍정'\n",
        "df.loc[(df['sentence'].str.contains('응') & df['sentence'].str.contains('맞아')), 'intent'] = '긍정'\n",
        "\n",
        "df.loc[(df['sentence'].str.contains('아니') & df['sentence'].str.contains('싫어')), 'intent'] = '부정'\n",
        "\n",
        "\n",
        "fst_P_key = ['맞어','맞아','마자','마쟈','마저','맞지','응 ','응!','응응 ','웅 ','웅웅 ','웅!','좋아 ','좋다']\n",
        "fst_N_key = ['아뇨','아니','아닌데','아녀','아니여','아냐','싫어 ','싫어,','싫어!','시러','싫은데','안돼','안되지','안된','별로야']\n",
        "\n",
        "for i in fst_P_key:\n",
        "    df.loc[(df['sentence'].str.startswith(i)), 'intent'] = '긍정'\n",
        "for i in fst_N_key:\n",
        "    df.loc[(df['sentence'].str.startswith(i)), 'intent'] = '부정'\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nY8KnI0c-ZC",
        "outputId": "d2ecdebe-344e-4dda-8624-2afcdf5dde7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(지시) 질문하기 170965\n",
            "(단언) 주장하기 243605\n",
            "(단언) 진술하기 213634\n",
            "긍정 46140\n",
            "(지시) 충고/제안하기 23482\n",
            "(표현) 부정감정 표현하기 5047\n",
            "(언약) 약속하기(제3자와)/(개인적 수준) 10114\n",
            "부정 11292\n",
            "(표현) 감사하기 1186\n",
            "턴토크 사인(관습적 반응) 2577\n",
            "(지시) 명령/요구하기 2037\n",
            "(지시) 부탁하기 3118\n",
            "(표현) 긍정감정 표현하기 4395\n",
            "(단언) 반박하기 2054\n",
            "(표현) 인사하기 344\n",
            "(표현) 사과하기 376\n",
            "(언약) 거절하기 269\n",
            "(선언/위임하기) 42\n"
          ]
        }
      ],
      "source": [
        "asdf = list(df['intent'].unique())\n",
        "for i in asdf :\n",
        "    print(i,df.loc[df['intent']==i,'intent'].count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1yyz25d2c-ZC"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"klue/bert-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "JVyfDGnbc-ZC",
        "outputId": "3187b218-a06c-4489-fc94-bae989ffa696"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 13, 2049, 1236, 1049, 1048]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'[CLS]. 아니는이어'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# token 바구니\n",
        "N_count = []\n",
        "\n",
        "# 필요 문장 추출\n",
        "N_intent = ['(표현) 부정감정 표현하기', '(단언) 반박하기', '(언약) 거절하기', '부정']\n",
        "\n",
        "# 필요 문장 구성하는 모든 token 바구니에 넣기\n",
        "for intent in N_intent :\n",
        "    for i in df.loc[(df['intent'] == intent), 'sentence']:\n",
        "        N_count += tokenizer.encode(i)\n",
        "\n",
        "# token 고유값과 개수 / N_uni[0] = 고유값 리스트 / N_uni[1] = 고유값 개수 리스트\n",
        "N_uni = np.unique(N_count, return_counts=True)\n",
        "\n",
        "# 고유값 개수 내림차순 정렬\n",
        "N_cnt = sorted(list(set(N_uni[1])),reverse=True)\n",
        "\n",
        "# N_many = N_uni[0]에서 검색할 index값 / N_token = 사용 횟수가 많은 token\n",
        "N_many = []\n",
        "N_token = []\n",
        "\n",
        "for i in N_cnt:\n",
        "    if i > 2700 :\n",
        "        N_many.append(list(N_uni[1]).index(i))\n",
        "for j in range(len(N_many)) :\n",
        "    N_token.append(N_uni[0][N_many[j]])\n",
        "print(N_many)\n",
        "\n",
        "tokenizer.decode(N_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "DLLthAMXc-ZD",
        "outputId": "9f7ea02a-5d5c-4d68-b995-aae4f2355275"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 813, 10990, 13, 1421, 1223, 1288, 1224, 1260, 1017]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'[CLS] 응 맞아.는어도이키 키'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# token 바구니\n",
        "P_count = []\n",
        "\n",
        "# 필요 문장 추출\n",
        "P_intent = ['(표현) 긍정감정 표현하기', '(표현) 감사하기', '긍정']\n",
        "\n",
        "# 필요 문장 구성하는 모든 token 바구니에 넣기\n",
        "for intent in P_intent :\n",
        "    for i in df.loc[(df['intent'] == intent), 'sentence']:\n",
        "        P_count += tokenizer.encode(i)\n",
        "\n",
        "# token 고유값과 개수 / N_uni[0] = 고유값 리스트 / N_uni[1] = 고유값 개수 리스트\n",
        "P_uni = np.unique(P_count, return_counts=True)\n",
        "\n",
        "# 고유값 개수 내림차순 정렬\n",
        "P_cnt = sorted(list(set(P_uni[1])),reverse=True)\n",
        "\n",
        "# N_many = N_uni[0]에서 검색할 index값 / N_token = 사용 횟수가 많은 token\n",
        "P_many = []\n",
        "P_token = []\n",
        "\n",
        "for i in P_cnt:\n",
        "    if i > 7700 :\n",
        "        P_many.append(list(P_uni[1]).index(i))\n",
        "for j in range(len(P_many)) :\n",
        "    P_token.append(P_uni[0][P_many[j]])\n",
        "print(P_many)\n",
        "\n",
        "tokenizer.decode(P_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "3Qpv00jFc-ZD",
        "outputId": "d50feacb-aac1-4d14-b546-83a308b34627"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 794, 10743, 13, 1390, 1194, 1259]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'[CLS] 응 맞아.는어도'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# token 바구니\n",
        "M_count = []\n",
        "\n",
        "# 필요 문장 추출\n",
        "M_intent = ['(단언) 진술하기', '(지시) 충고/제안하기', '(단언) 주장하기', '(지시) 질문하기', '(지시) 부탁하기',\n",
        "        '(표현) 사과하기', '(지시) 명령/요구하기', '턴토크 사인(관습적 반응)',\n",
        "       '(언약) 약속하기(제3자와)/(개인적 수준)', '(표현) 인사하기', '(선언/위임하기)']\n",
        "\n",
        "# 필요 문장 구성하는 모든 token 바구니에 넣기\n",
        "for intenti in range(len(M_intent)):\n",
        "    if df.loc[(df['intent'] == intent), 'sentence'].count() > 1000:\n",
        "        for i in (df.loc[(df['intent'] == intent), 'sentence']):\n",
        "            M_count += tokenizer.encode(i)\n",
        "    else:\n",
        "        for i in (df.loc[(df['intent'] == intent), 'sentence']):\n",
        "            M_count += tokenizer.encode(i)\n",
        "\n",
        "# token 고유값과 개수 / N_uni[0] = 고유값 리스트 / N_uni[1] = 고유값 개수 리스트\n",
        "M_uni = np.unique(M_count, return_counts=True)\n",
        "\n",
        "# 고유값 개수 내림차순 정렬\n",
        "M_cnt = sorted(list(set(M_uni[1])),reverse=True)\n",
        "\n",
        "# M_many = N_uni[0]에서 검색할 index값 / M_token = 사용 횟수가 많은 token\n",
        "M_many = []\n",
        "M_token = []\n",
        "\n",
        "for i in M_cnt:\n",
        "    if i > 100000 :\n",
        "        M_many.append(list(M_uni[1]).index(i))\n",
        "for j in range(len(M_many)) :\n",
        "    M_token.append(M_uni[0][M_many[j]])\n",
        "print(M_many)\n",
        "\n",
        "tokenizer.decode(M_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pqg5Eswzc-ZE",
        "outputId": "4f1b7fd0-565f-4351-d049-3c5f2dda8dee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "아니\n",
            "##키 키\n"
          ]
        }
      ],
      "source": [
        "# 중복값 제거\n",
        "print(tokenizer.decode((set(N_token).difference(set(P_token))).difference(set(M_token))))\n",
        "print(tokenizer.decode((set(P_token).difference(set(N_token))).difference(set(M_token))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "K5emQt24c-ZE"
      },
      "outputs": [],
      "source": [
        "N_keyword = ['싫어\\.\\.', '아니']\n",
        "P_keyword = ['맞아', '응응', '응\\.', '응,']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xmYrzmYdc-ZE"
      },
      "outputs": [],
      "source": [
        "# 부정키워드 포함 긍정문장 제거\n",
        "for intent in P_intent:\n",
        "    for key in N_keyword:\n",
        "        df.drop(df.loc[(df['intent'] == intent) & df['sentence'].str.contains(key)].index, axis=0, inplace=True)\n",
        "\n",
        "# 긍정키워드 포함 부정문장 제거\n",
        "for intent in N_intent:\n",
        "    for key in P_keyword:\n",
        "        df.drop(df.loc[(df['intent'] == intent) & df['sentence'].str.contains(key)].index, axis=0, inplace=True)\n",
        "\n",
        "# 필요한 데이터를 추출하기 위한 DataFrame 생성\n",
        "temp_df = pd.DataFrame()\n",
        "temp = pd.DataFrame()\n",
        "df_ = copy.deepcopy(df)\n",
        "\n",
        "# 기존 데이터에서 긍정, 부정 문장 제거\n",
        "for intent in (N_intent+P_intent):\n",
        "    df_.drop(df_[df_['intent'] == intent].index, axis=0, inplace=True)\n",
        "\n",
        "# 남은 중립문장 중 필요한만큼 문장 추출\n",
        "temp_df = pd.concat([temp_df,df_.sample(n=130000)], ignore_index=True)\n",
        "\n",
        "# 중립문장 중 긍정/부정 키워드 포함한 문장 제거\n",
        "for key in (N_keyword+P_keyword):\n",
        "    temp_df.drop(temp_df.loc[temp_df['sentence'].str.contains(key)].index, axis=0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0LyW_USc-ZF",
        "outputId": "683d4663-fa87-468f-cde0-4fb3db270e65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(표현) 부정감정 표현하기\n",
            "(단언) 반박하기\n",
            "(언약) 거절하기\n",
            "부정\n",
            "(표현) 긍정감정 표현하기\n",
            "(표현) 감사하기\n",
            "긍정\n",
            "====================================================================================================\n",
            "(표현) 부정감정 표현하기\n",
            "(단언) 반박하기\n",
            "(언약) 거절하기\n",
            "부정\n",
            "(표현) 긍정감정 표현하기\n",
            "(표현) 감사하기\n",
            "긍정\n",
            "(지시) 질문하기\n",
            "(지시) 충고/제안하기\n",
            "(단언) 진술하기\n",
            "(단언) 주장하기\n",
            "(언약) 약속하기(제3자와)/(개인적 수준)\n",
            "턴토크 사인(관습적 반응)\n",
            "(지시) 부탁하기\n",
            "(지시) 명령/요구하기\n",
            "(표현) 사과하기\n",
            "(표현) 인사하기\n",
            "(선언/위임하기)\n",
            "                          sentence          intent\n",
            "0                    저런... 정말 힘들겠다  (표현) 부정감정 표현하기\n",
            "1                        습한 느낌이 싫어  (표현) 부정감정 표현하기\n",
            "2                  대단한데? 난 무서워서 못해  (표현) 부정감정 표현하기\n",
            "3                    그런거같아 너무 머리아파  (표현) 부정감정 표현하기\n",
            "4             진료 받는 것도 무섭고 돈도 무서워~  (표현) 부정감정 표현하기\n",
            "...                            ...             ...\n",
            "195415        요즘 아르바이트 하니 예전 생각 난다       (단언) 진술하기\n",
            "195416               그래 처음에는 그랬겠구먼       (단언) 진술하기\n",
            "195417   팔 흔들고 다니는건 무리하게 되는게 아닌걸까?       (지시) 질문하기\n",
            "195418        찌개 맛 때문에 별 차이 없지 않아?       (지시) 질문하기\n",
            "195419  아무리 신차라도 판매도 못하는걸 전시할라나...       (단언) 주장하기\n",
            "\n",
            "[195420 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# 필요한만큼 긍정/부정문장 추출\n",
        "for intent in (N_intent+P_intent):\n",
        "    print(intent)\n",
        "    if df.loc[df['intent']==intent, 'intent'].count() > 100000:\n",
        "        temp = pd.concat([temp,df[df['intent'] == intent].sample(n=100000)], ignore_index=True)\n",
        "    # elif df.loc[df['intent']==intent, 'intent'].count() > 10000:\n",
        "    #     temp = pd.concat([temp,df[df['intent'] == intent].sample(n=10000)], ignore_index=True)\n",
        "    else :\n",
        "        temp = pd.concat([temp,df[df['intent'] == intent]], ignore_index=True)\n",
        "\n",
        "temp = pd.concat([temp,temp_df], ignore_index=True)\n",
        "\n",
        "print('='*100)\n",
        "for i in list(temp['intent'].unique()):\n",
        "  print(i)\n",
        "\n",
        "print(temp)\n",
        "\n",
        "temp.loc[(temp['intent'] == '(표현) 부정감정 표현하기')|(temp['intent'] == '(언약) 거절하기')|\n",
        "         (temp['intent'] == '(단언) 반박하기'), 'intent'] = '부정'\n",
        "temp.loc[(temp['intent'] == '(표현) 긍정감정 표현하기')|(temp['intent'] == '(표현) 감사하기'), 'intent'] = '긍정'\n",
        "temp.loc[(temp['intent'] != '부정')&(temp['intent'] != '긍정'), 'intent'] = '중립'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "kXFFJsnOc-ZF"
      },
      "outputs": [],
      "source": [
        "fin_df = copy.deepcopy(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erhvAH6Pc-ZF",
        "outputId": "97dc66b7-b069-4f64-f1d7-dda22087cda6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "부정 18581\n",
            "긍정 50929\n",
            "중립 125910\n"
          ]
        }
      ],
      "source": [
        "temp = list(fin_df['intent'].unique())\n",
        "for i in temp :\n",
        "    print(i,fin_df.loc[fin_df['intent']==i,'intent'].count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJ00xoZ3RrXF",
        "outputId": "b79693ff-c8bd-47d7-a7e5-48c75da84f13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 클래수 개수\n",
        "lable_num = len(fin_df['intent'].unique())\n",
        "lable_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "A4eCP2zgivIz",
        "outputId": "a6d73cb6-2364-4e00-96b5-f22abcbb8971"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: '긍정', 1: '부정', 2: '중립'}\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>intent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>웃겨 증말</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>나 그거 1편 밖에 안 봤어</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>어때 반대해? 찬성해</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>맞아 키키 거긴 사람들이 다 평점 좋아</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>난또보고싶은데</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195415</th>\n",
              "      <td>말년 휴가는 꼭 나와야지 당연히 ㅠㅠ</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195416</th>\n",
              "      <td>혹시 요리중에 어떤 걸 잘하세요</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195417</th>\n",
              "      <td>야근도 시켜 거긴?</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195418</th>\n",
              "      <td>쇼핑몰 쿠폰 잘 주는 데 알아?</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195419</th>\n",
              "      <td>그렇지 경제학과 미적분 못해서 난리였잖아</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>195420 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      sentence intent\n",
              "0                        웃겨 증말      2\n",
              "1              나 그거 1편 밖에 안 봤어      2\n",
              "2                  어때 반대해? 찬성해      2\n",
              "3        맞아 키키 거긴 사람들이 다 평점 좋아      0\n",
              "4                      난또보고싶은데      2\n",
              "...                        ...    ...\n",
              "195415    말년 휴가는 꼭 나와야지 당연히 ㅠㅠ      2\n",
              "195416       혹시 요리중에 어떤 걸 잘하세요      2\n",
              "195417              야근도 시켜 거긴?      2\n",
              "195418       쇼핑몰 쿠폰 잘 주는 데 알아?      2\n",
              "195419  그렇지 경제학과 미적분 못해서 난리였잖아      2\n",
              "\n",
              "[195420 rows x 2 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_dict = {0: '긍정', 1: '부정', 2: '중립'}\n",
        "\n",
        "for idx, intent_lab in label_dict.items() :\n",
        "    fin_df.loc[fin_df['intent'] == intent_lab, 'intent'] = idx\n",
        "\n",
        "print(label_dict)\n",
        "fin_df = fin_df.sample(frac=1).reset_index(drop=True)\n",
        "fin_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kiw-yqCbivI0",
        "outputId": "8236e231-c8d7-4ea7-93b4-78a2ff1f80c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                     sentence intent\n",
            "0                       웃겨 증말      2\n",
            "1             나 그거 1편 밖에 안 봤어      2\n",
            "2                 어때 반대해? 찬성해      2\n",
            "3       맞아 키키 거긴 사람들이 다 평점 좋아      0\n",
            "4                     난또보고싶은데      2\n",
            "...                       ...    ...\n",
            "156332            아 그거 마약 아녀?      2\n",
            "156333             벚꽃 구경도 못했다      2\n",
            "156334         라고 소스인데 흰 버전이야      2\n",
            "156335       웅 올해 받으면 4년째라던데?      0\n",
            "156336     일렉기타는 너무 시끄럽지 않을까?      2\n",
            "\n",
            "[156337 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "train_data = pd.DataFrame()\n",
        "\n",
        "len_ = fin_df['intent'].count()\n",
        "\n",
        "train_data = pd.concat([train_data,fin_df.loc[:(len_*8)/10]],ignore_index=True)\n",
        "print(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Su9DTBRMoXcI",
        "outputId": "54f64c90-6886-4f96-b44c-951f0810e138"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                     sentence intent\n",
            "0          일렉기타는 너무 시끄럽지 않을까?      2\n",
            "1      맞아 나이키 공식 홈페이지에서 배송해준대      0\n",
            "2             왜 키키 물을 소독을 해서?      2\n",
            "3           응 엄마가 등산을 좋아하시더라고      0\n",
            "4      가수는 당연히 노래 잘 하는 게 중요하지      0\n",
            "...                       ...    ...\n",
            "39079    말년 휴가는 꼭 나와야지 당연히 ㅠㅠ      2\n",
            "39080       혹시 요리중에 어떤 걸 잘하세요      2\n",
            "39081              야근도 시켜 거긴?      2\n",
            "39082       쇼핑몰 쿠폰 잘 주는 데 알아?      2\n",
            "39083  그렇지 경제학과 미적분 못해서 난리였잖아      2\n",
            "\n",
            "[39084 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "test_data = pd.DataFrame()\n",
        "\n",
        "len_ = fin_df['intent'].count()\n",
        "\n",
        "test_data = pd.concat([test_data,fin_df.loc[(len_*8)/10:]],ignore_index=True)\n",
        "print(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fL0xFDtcivI0",
        "outputId": "8db4e551-0f03-427e-b571-0962ae90ef63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n",
            "문 장1 : 웃겨 증말\n"
          ]
        }
      ],
      "source": [
        "max_seq_len = max(df['sentence'].apply(lambda x: len(str(x))))\n",
        "\n",
        "sent1 = train_data['sentence'].iloc[0]\n",
        "print(max_seq_len)\n",
        "print('문 장1 :',sent1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-9AZdytivI0",
        "outputId": "87598214-6cf4-4a48-f97e-9d39d5239624"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2, 18281, 1582, 2231, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "길 이 : 100\n"
          ]
        }
      ],
      "source": [
        "# 정수인코딩\n",
        "encoded_result = tokenizer(sent1, max_length=max_seq_len, padding='max_length', truncation=True)['input_ids']\n",
        "print(encoded_result)\n",
        "print('길 이 :', len(encoded_result))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz0dGmpkivI1",
        "outputId": "21c677ae-8b64-4325-f330-94e3d7b6d9db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "# 세그멘트인코딩\n",
        "print([0]*max_seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HD9XCiqHivI1",
        "outputId": "5e43266a-f029-4374-dbe8-575ee832fe2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "# 어텐션마스크인코딩\n",
        "valid_num = len(tokenizer.encode(sent1))\n",
        "print(valid_num * [1] + (max_seq_len - valid_num) * [0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "wbVNVsL4ivI1"
      },
      "outputs": [],
      "source": [
        "def convert_examples_to_features(examples, labels, max_seq_len, tokenizer):\n",
        "\n",
        "    input_ids, attention_masks, token_type_ids, data_labels = [], [], [], []\n",
        "\n",
        "    for example, label in tqdm(zip(examples, labels), total=len(examples)):\n",
        "        # input_id는 워드임베딩을 위한 문장의 정수인코딩\n",
        "        input_id = tokenizer(example, max_length=max_seq_len, padding='max_length', truncation=True)['input_ids']\n",
        "\n",
        "        # attention_mask는 실제단어가 위치하면 1, 패딩의 위치에는 0인 시퀀스.\n",
        "        padding_count = input_id.count(tokenizer.pad_token_id)\n",
        "        attention_mask = [1] * (max_seq_len - padding_count) + [0] * padding_count\n",
        "\n",
        "        # token_type_id은 세그먼트인코딩\n",
        "        token_type_id = [0] * max_seq_len\n",
        "\n",
        "        assert len(input_id) == max_seq_len, \"Error with input length {} vs {}\".format(len(input_id), max_seq_len)\n",
        "        assert len(attention_mask) == max_seq_len, \"Error with attention masklength {} vs {}\".format(len(attention_mask), max_seq_len)\n",
        "        assert len(token_type_id) == max_seq_len, \"Error with token type length{} vs {}\".format(len(token_type_id), max_seq_len)\n",
        "\n",
        "        input_ids.append(input_id)\n",
        "        attention_masks.append(attention_mask)\n",
        "        token_type_ids.append(token_type_id)\n",
        "        data_labels.append(label)\n",
        "\n",
        "    input_ids = np.array(input_ids, dtype=int)\n",
        "    attention_masks = np.array(attention_masks, dtype=int)\n",
        "    token_type_ids = np.array(token_type_ids, dtype=int)\n",
        "\n",
        "    data_labels = np.asarray(data_labels, dtype=np.int32)\n",
        "\n",
        "    return (input_ids, attention_masks, token_type_ids), data_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojORc4IFivI1",
        "outputId": "2dabbac1-0410-4a44-9ba7-e7222d456c38"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 156337/156337 [00:19<00:00, 8109.72it/s]\n"
          ]
        }
      ],
      "source": [
        "train_X, train_y = convert_examples_to_features(train_data['sentence'], train_data['intent'],\n",
        "                                              max_seq_len=max_seq_len, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_K9jSOSwivI1",
        "outputId": "9181065c-09e2-436d-ed44-b50bb2c2aa1e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/39084 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 39084/39084 [00:04<00:00, 8479.82it/s]\n"
          ]
        }
      ],
      "source": [
        "test_X, test_y = convert_examples_to_features(test_data['sentence'], test_data['intent'],\n",
        "                                              max_seq_len=max_seq_len, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFrRthhJivI2",
        "outputId": "90aba148-6565-4af4-a3e9-17101cc16c49"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1763233912.622286   11643 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1920 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
            "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n"
          ]
        }
      ],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "model = TFBertForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=lable_num, from_pt=True)\n",
        "model.compile(optimizer=optimizer, loss=model.hf_compute_loss, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-r3BZ9nLivI2",
        "outputId": "ada3ff0c-05da-4cfa-a727-1e31a02b2e0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "1144/1144 [==============================] - 365s 280ms/step - loss: 0.1897 - accuracy: 0.9366 - val_loss: 0.1679 - val_accuracy: 0.9431\n",
            "Epoch 2/4\n",
            "1144/1144 [==============================] - 308s 269ms/step - loss: 0.1533 - accuracy: 0.9454 - val_loss: 0.1702 - val_accuracy: 0.9446\n",
            "Epoch 3/4\n",
            "1144/1144 [==============================] - 308s 269ms/step - loss: 0.1228 - accuracy: 0.9527 - val_loss: 0.1818 - val_accuracy: 0.9390\n",
            "Epoch 4/4\n",
            "1144/1144 [==============================] - 308s 269ms/step - loss: 0.0820 - accuracy: 0.9679 - val_loss: 0.2252 - val_accuracy: 0.9286\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f55bdaf6110>"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(train_X, train_y, epochs=4, batch_size=128, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2W1p9gcJivI2",
        "outputId": "e4f2efad-f6aa-4fce-883c-fc367fd16e02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "715/715 [==============================] - 38s 53ms/step - loss: 0.2238 - accuracy: 0.9285\n",
            "test loss, test acc:  [0.22375456988811493, 0.9285027384757996]\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate(test_X, test_y, batch_size=64)\n",
        "print(\"test loss, test acc: \", results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09Y1pSHxivI2"
      },
      "outputs": [],
      "source": [
        "def sentiment_predict(new_sentence):\n",
        "    input_id = tokenizer.encode(new_sentence, max_length=max_seq_len, pad_to_max_length=True)\n",
        "\n",
        "    padding_count = input_id.count(tokenizer.pad_token_id)\n",
        "    attention_mask = [1] * (max_seq_len - padding_count) + [0] * padding_count\n",
        "    token_type_id = [0] * max_seq_len\n",
        "\n",
        "    input_ids = np.array([input_id])\n",
        "    attention_masks = np.array([attention_mask])\n",
        "    token_type_ids = np.array([token_type_id])\n",
        "\n",
        "    encoded_input = [input_ids, attention_masks, token_type_ids]\n",
        "\n",
        "    score = np.argmax(model.predict(encoded_input)[0])\n",
        "\n",
        "    print('sentence :',new_sentence)\n",
        "    print(label_dict[score])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUicj3_uivI2",
        "outputId": "18dc77bf-be3c-4152-93a7-bfc1e2005aee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Drive/MyDrive/NP_classifier/NP_classifier\n",
            "/content/Drive/MyDrive/NP_classifier/NP_classifier -- Folder create complete \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('/content/Drive/MyDrive/NP_classifier/NP_classifier/tokenizer_config.json',\n",
              " '/content/Drive/MyDrive/NP_classifier/NP_classifier/special_tokens_map.json',\n",
              " '/content/Drive/MyDrive/NP_classifier/NP_classifier/vocab.txt',\n",
              " '/content/Drive/MyDrive/NP_classifier/NP_classifier/added_tokens.json')"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MODEL_SAVE_PATH = os.path.join(\"/content/Drive/MyDrive/NP_classifier/NP_classifier\")\n",
        "print(MODEL_SAVE_PATH)\n",
        "\n",
        "if os.path.exists(MODEL_SAVE_PATH):\n",
        "    print(f\"{MODEL_SAVE_PATH} -- Folder already exists \\n\")\n",
        "\n",
        "else:\n",
        "    os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
        "    print(f\"{MODEL_SAVE_PATH} -- Folder create complete \\n\")\n",
        "\n",
        "model.save_pretrained(MODEL_SAVE_PATH)\n",
        "tokenizer.save_pretrained(MODEL_SAVE_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1InHBDrNivI2",
        "outputId": "e274762d-3d65-4a7a-92bc-aca4bafcd4b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sentence > 인공지능 재미있네!\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "sentence : 인공지능 재미있네!\n",
            "긍정\n"
          ]
        }
      ],
      "source": [
        "new_sentence = input('sentence > ')\n",
        "sentiment_predict(new_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFCDr-yMvW2X"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuClass": "premium",
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "tf-gpu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
